{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userID  itemID  score\n",
      "0  199808  248969     90\n",
      "1  199808    2663     90\n",
      "2  199808   28341     90\n",
      "3  199808   42563     90\n",
      "4  199808   59092     90\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "file_name_test = \"data/\" + 'testTrack_hierarchy.txt'\n",
    "file_name_train = \"data/\" + 'trainIdx2_matrix.txt'\n",
    "output_file = 'output1.txt'\n",
    "\n",
    "# Load the training data into a DataFrame\n",
    "train_data = pd.read_csv(file_name_train, sep='|', header=None, names=[\"userID\", \"itemID\", \"score\"])\n",
    "\n",
    "# Prepare the dataset for matrix factorization\n",
    "reader = Reader(rating_scale=(train_data['score'].min(), train_data['score'].max()))\n",
    "data = Dataset.load_from_df(train_data, reader)\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 25.775363641911724\n",
      "Best parameters: {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x4932248e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into a training set and a validation set\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Grid search for finding the best hyperparameters\n",
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10, 20],\n",
    "    \"lr_all\": [0.002, 0.005, 0.01],\n",
    "    \"reg_all\": [0.02, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "\n",
    "print(\"Best RMSE score:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best parameters:\", gs.best_params[\"rmse\"])\n",
    "\n",
    "# Train the SVD model using the best hyperparameters\n",
    "algorithm = gs.best_estimator[\"rmse\"]\n",
    "algorithm.fit(trainset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list = []\n",
    "\n",
    "with open(file_name_test, 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('|')\n",
    "        user_id, track_id, album_id, artist_id = fields[:4]\n",
    "        genres = fields[4:]\n",
    "\n",
    "        test_data_list.append({\n",
    "            \"userID\": user_id,\n",
    "            \"trackID\": track_id,\n",
    "            \"albumID\": album_id,\n",
    "            \"artistID\": artist_id,\n",
    "            \"genres\": genres\n",
    "        })\n",
    "\n",
    "test_data = pd.DataFrame(test_data_list)\n",
    "\n",
    "# Predict the user preference scores for the test dataset\n",
    "predictions = []\n",
    "for index, row in test_data.iterrows():\n",
    "    user_id, track_id, album_id, artist_id = row[\"userID\"], row[\"trackID\"], row[\"albumID\"], row[\"artistID\"]\n",
    "    \n",
    "    # Predict the ratings for the album and artist using the trained model, if available\n",
    "    album_pred = algorithm.predict(user_id, album_id) if album_id != 'None' else 0\n",
    "    artist_pred = algorithm.predict(user_id, artist_id) if artist_id != 'None' else 0\n",
    "    \n",
    "\n",
    "    alb_pred = album_pred.est if album_pred else 0\n",
    "    art_pred=  artist_pred.est if artist_pred else 0\n",
    "\t\n",
    "    # Calculate the total rating\n",
    "    total_rating = alb_pred + art_pred\n",
    "        \n",
    "    # Apply threshold for binary output (1 if the user would like it, 0 otherwise)\n",
    "    like_or_not = 1 if total_rating >= 0.5 else 0\n",
    "    \n",
    "    predictions.append([f\"{user_id}_{track_id}\", like_or_not])\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=[\"TrackID\", \"Predictor\"])\n",
    "predictions_df.to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
