{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 22128003\n",
      "Filtered row count: 22128002\n",
      "Percentage of data removed: 0.00%\n",
      "          trackId albumId artistId    userId  rating                   genres\n",
      "21224082   204650  177418   131552  199810.0    50.0                       []\n",
      "10586553     9774   79500   158282  199810.0    50.0         [242383, 207648]\n",
      "5006151      9774   79500   158282  199810.0    50.0  [242383, 207648, 47898]\n",
      "5146696     26374  153568   158282  199810.0    50.0          [81520, 242383]\n",
      "10580710   271229  293464   279143  199811.0    70.0          [173655, 98154]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# Change this value to set the minimum number of ratings required per user\n",
    "min_ratings_threshold = 0\n",
    "\n",
    "training_data_dir = '../data/trainIdx2_matrix.txt'\n",
    "track_data_dir = '../data/trackData2.txt'\n",
    "output_dir = \"../data/proccessed/dump.csv\"\n",
    "# Read the training data\n",
    "train_df = pd.read_csv(training_data_dir, sep='|',\n",
    "                       names=['userId', 'itemId', 'rating'])\n",
    "\n",
    "\n",
    "# Read the track data line by line\n",
    "with open(track_data_dir, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "track_data = []\n",
    "for line in lines:\n",
    "    fields = line.strip().split('|')\n",
    "    # Use the second number as the trackId\n",
    "    track_data.append([fields[1]] + fields[2:])\n",
    "\n",
    "# Create a DataFrame from the track data\n",
    "track_data_df = pd.DataFrame(track_data)\n",
    "\n",
    "# Fill NaN values with an empty string\n",
    "track_data_df.fillna(\"\", inplace=True)\n",
    "\n",
    "# Determine the maximum number of genres\n",
    "max_genres = track_data_df.shape[1] - 3\n",
    "\n",
    "# Rename columns\n",
    "track_data_df.columns = ['trackId', 'albumId', 'artistId'] + \\\n",
    "    [f'genreId_{i}' for i in range(1, max_genres + 1)]\n",
    "\n",
    "# Convert the 'itemId' columns to numeric and drop any rows with non-finite values\n",
    "train_df['itemId'] = pd.to_numeric(train_df['itemId'], errors='coerce')\n",
    "train_df.dropna(subset=['itemId'], inplace=True)\n",
    "\n",
    "track_data_df['trackId'] = pd.to_numeric(\n",
    "    track_data_df['trackId'], errors='coerce')\n",
    "track_data_df.dropna(subset=['trackId'], inplace=True)\n",
    "\n",
    "# Convert the 'itemId' columns to int data type\n",
    "train_df['itemId'] = train_df['itemId'].astype(int)\n",
    "track_data_df['trackId'] = track_data_df['trackId'].astype(int)\n",
    "\n",
    "# Merge the track data with the train data\n",
    "merged_df = track_data_df.merge(\n",
    "    train_df, left_on='trackId', right_on='itemId', how='left')\n",
    "\n",
    "# Convert genres to a list of genres for each track\n",
    "merged_df['genres'] = merged_df[[\n",
    "    f'genreId_{i}' for i in range(1, max_genres + 1)]].values.tolist()\n",
    "\n",
    "# Remove empty strings from the genre lists\n",
    "merged_df['genres'] = merged_df['genres'].apply(\n",
    "    lambda x: [genre for genre in x if genre != \"\"])\n",
    "\n",
    "# Drop individual genre columns and itemId column\n",
    "merged_df.drop(columns=[f'genreId_{i}' for i in range(\n",
    "    1, max_genres + 1)] + ['itemId'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Filter out users who have fewer than the threshold number of ratings\n",
    "user_rating_counts = merged_df['userId'].value_counts()\n",
    "users_with_min_ratings = user_rating_counts[user_rating_counts >=\n",
    "                                            min_ratings_threshold].index\n",
    "filtered_df = merged_df[merged_df['userId'].isin(users_with_min_ratings)]\n",
    "\n",
    "# Calculate the number of rows in the original and filtered DataFrames\n",
    "original_row_count = len(merged_df)\n",
    "filtered_row_count = len(filtered_df)\n",
    "\n",
    "# Calculate the percentage of rows removed\n",
    "percentage_removed = (\n",
    "    (original_row_count - filtered_row_count) / original_row_count) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Original row count: {original_row_count}\")\n",
    "print(f\"Filtered row count: {filtered_row_count}\")\n",
    "print(f\"Percentage of data removed: {percentage_removed:.2f}%\")\n",
    "\n",
    "\n",
    "# Continue with the rest of the recommendation system using the filtered_df DataFrame\n",
    "merged_df = filtered_df.sort_values(by='userId')\n",
    "\n",
    "print(merged_df.head())\n",
    "merged_df.to_csv(output_dir, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
