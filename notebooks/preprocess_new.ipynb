{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:352816.0\n",
      "Count: 6000\n",
      "Average: 58.80266666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "truth_data = defaultdict(dict)\n",
    "train_data = defaultdict(dict)\n",
    "\n",
    "with open(\"../data/test2_new.txt\", 'r') as fTruth:\n",
    "    next(fTruth)  # Skip the header row\n",
    "    for line in fTruth:\n",
    "        trainUserID, trainItemID, trainRating = line.strip().split('|')\n",
    "        truth_data[trainUserID][trainItemID] = int(trainRating)\n",
    "\n",
    "with open(\"../data/trainIdx2_matrix.txt\", 'r') as fTrain:\n",
    "    next(fTrain)  # Skip the header row\n",
    "    for line in fTrain:\n",
    "        trainUserID, trainItemID, trainRating = line.strip().split('|')\n",
    "        train_data[trainUserID][trainItemID] = int(trainRating)\n",
    "\n",
    "track_rating_data = defaultdict(list)\n",
    "\n",
    "for user_ratings in train_data.values():\n",
    "    for trackID, rating in user_ratings.items():\n",
    "        track_rating_data[trackID].append(rating)\n",
    "\n",
    "track_stats = {}\n",
    "for trackID, ratings in track_rating_data.items():\n",
    "    ratings_array = np.array(ratings)\n",
    "    track_stats[trackID] = {\n",
    "        'min': np.min(ratings_array),\n",
    "        'max': np.max(ratings_array),\n",
    "        'mean': np.mean(ratings_array),\n",
    "        'variance': np.var(ratings_array),\n",
    "        'median': np.median(ratings_array)\n",
    "    }\n",
    "\n",
    "with open(\"../data/testTrack_hierarchy.txt\", 'r') as fTest, open(\"../data/proccessed/new.csv\", 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow([\"UserId\", \"TrackId\", \"AlbumId\", \"ArtistId\", \"AlbumRating\", \"ArtistRating\", \"TotalScore\", \"Predictor\",\n",
    "                         \"MinRating\", \"MaxRating\", \"MeanRating\", \"Variance\", \"MedianRating\"])\n",
    "\n",
    "    trackID_vec = [0] * 6\n",
    "    albumID_vec = [0] * 6\n",
    "    artistID_vec = [0] * 6\n",
    "    lastUserID = -1\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for line in fTest:\n",
    "        userID, trackID, albumID, artistID, *_ = line.strip().split('|')\n",
    "\n",
    "        if userID != lastUserID:\n",
    "            ii = 0\n",
    "            user_rating_inTrain = np.zeros(shape=(6, 2))\n",
    "\n",
    "        trackID_vec[ii] = trackID\n",
    "        albumID_vec[ii] = albumID\n",
    "        artistID_vec[ii] = artistID\n",
    "        ii += 1\n",
    "        lastUserID = userID\n",
    "\n",
    "        if userID not in truth_data:\n",
    "            continue\n",
    "\n",
    "        if ii == 6:\n",
    "            user_train_data = train_data[userID]\n",
    "\n",
    "            for nn in range(6):\n",
    "                user_rating_inTrain[nn] = [\n",
    "                                           user_train_data.get(\n",
    "                                               albumID_vec[nn], 0),\n",
    "                                           user_train_data.get(artistID_vec[nn], 0)]\n",
    "            for nn in range(6):\n",
    "                total_score = sum(user_rating_inTrain[nn])\n",
    "                total_sum += total_score\n",
    "                total_count += 1\n",
    "                prediction = truth_data[userID][trackID_vec[nn]]\n",
    "                track_stat = track_stats.get(trackID_vec[nn], {})\n",
    "\n",
    "                csv_writer.writerow([userID, trackID_vec[nn], albumID_vec[nn],\n",
    "                                     artistID_vec[nn], *\n",
    "                                     user_rating_inTrain[nn], total_score, prediction,\n",
    "                                     track_stat.get(\n",
    "                                         'min', 0), track_stat.get('max', 0),\n",
    "                                     track_stat.get('mean', 0), track_stat.get(\n",
    "                                         'variance', 0),\n",
    "                                     track_stat.get('median', 0)])\n",
    "\n",
    "print(\"Total:\" + str(total_sum))\n",
    "print(\"Count: \" + str(total_count))\n",
    "print(\"Average: \" + str(total_sum/total_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/05/08 21:33:05 WARN Utils: Your hostname, BryanDesktop resolves to a loopback address: 127.0.1.1; using 172.23.1.37 instead (on interface eth0)\n",
      "23/05/08 21:33:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/08 21:33:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/08 21:33:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/05/08 21:33:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+--------+-----------+------------+----------+---------+---------+---------+-----------------+------------------+------------+\n",
      "|UserId|TrackId|AlbumId|ArtistId|AlbumRating|ArtistRating|TotalScore|Predictor|MinRating|MaxRating|       MeanRating|          Variance|MedianRating|\n",
      "+------+-------+-------+--------+-----------+------------+----------+---------+---------+---------+-----------------+------------------+------------+\n",
      "|200031|  30877| 192723|  132319|       90.0|        50.0|     140.0|        1|        0|      100|53.42664670658683|1195.6428228871598|        60.0|\n",
      "|200031|   8244| 223220|  233697|       90.0|         0.0|      90.0|        1|        0|      100|55.75752773375594|1216.3168014948726|        70.0|\n",
      "|200031| 130183|   None|    None|        0.0|         0.0|       0.0|        0|        0|       90|57.69230769230769| 1063.905325443787|        70.0|\n",
      "|200031| 198762| 220103|  113265|        0.0|         0.0|       0.0|        0|        0|      100|68.88888888888889| 1017.283950617284|        90.0|\n",
      "|200031|  34503|  43738|  173170|       90.0|        50.0|     140.0|        1|        0|      100|48.66293706293706|1197.5675074575774|        50.0|\n",
      "+------+-------+-------+--------+-----------+------------+----------+---------+---------+---------+-----------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from pyspark.sql.functions import split, col, avg\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('recommend-ML').getOrCreate()\n",
    "# import test_2 ground truths\n",
    "data_dir = \"../data/proccessed/new.csv\"\n",
    "df = spark.read.csv(data_dir, header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
