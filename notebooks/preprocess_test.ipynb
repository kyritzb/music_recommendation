{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:7044150.0\n",
      "Count: 120000\n",
      "Average: 58.70125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "truth_data = defaultdict(dict)\n",
    "train_data = defaultdict(dict)\n",
    "\n",
    "\n",
    "with open(\"../data/trainIdx2_matrix.txt\", 'r') as fTrain:\n",
    "    next(fTrain)  # Skip the header row\n",
    "    for line in fTrain:\n",
    "        trainUserID, trainItemID, trainRating = line.strip().split('|')\n",
    "        train_data[trainUserID][trainItemID] = int(trainRating)\n",
    "\n",
    "track_rating_data = defaultdict(list)\n",
    "\n",
    "for user_ratings in train_data.values():\n",
    "    for trackID, rating in user_ratings.items():\n",
    "        track_rating_data[trackID].append(rating)\n",
    "\n",
    "track_stats = {}\n",
    "for trackID, ratings in track_rating_data.items():\n",
    "    ratings_array = np.array(ratings)\n",
    "    track_stats[trackID] = {\n",
    "        'min': np.min(ratings_array),\n",
    "        'max': np.max(ratings_array),\n",
    "        'mean': np.mean(ratings_array),\n",
    "        'variance': np.var(ratings_array),\n",
    "        'median': np.median(ratings_array)\n",
    "    }\n",
    "\n",
    "with open(\"../data/testTrack_hierarchy.txt\", 'r') as fTest, open(\"../data/proccessed/test.csv\", 'w', newline='') as fOut:\n",
    "    csv_writer = csv.writer(fOut)\n",
    "    csv_writer.writerow([\"UserId\", \"TrackId\", \"AlbumId\", \"ArtistId\", \"AlbumRating\", \"ArtistRating\", \"TotalScore\",\n",
    "                         \"MinRating\", \"MaxRating\", \"MeanRating\", \"Variance\", \"MedianRating\"])\n",
    "\n",
    "    trackID_vec = [0] * 6\n",
    "    albumID_vec = [0] * 6\n",
    "    artistID_vec = [0] * 6\n",
    "    lastUserID = -1\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for line in fTest:\n",
    "        userID, trackID, albumID, artistID, *_ = line.strip().split('|')\n",
    "\n",
    "        if userID != lastUserID:\n",
    "            ii = 0\n",
    "            user_rating_inTrain = np.zeros(shape=(6, 2))\n",
    "\n",
    "        trackID_vec[ii] = trackID\n",
    "        albumID_vec[ii] = albumID\n",
    "        artistID_vec[ii] = artistID\n",
    "        ii += 1\n",
    "        lastUserID = userID\n",
    "\n",
    "        if ii == 6:\n",
    "            user_train_data = train_data[userID]\n",
    "\n",
    "            for nn in range(6):\n",
    "                user_rating_inTrain[nn] = [\n",
    "                                           user_train_data.get(\n",
    "                                               albumID_vec[nn], 0),\n",
    "                                           user_train_data.get(artistID_vec[nn], 0)]\n",
    "            for nn in range(6):\n",
    "                total_score = sum(user_rating_inTrain[nn])\n",
    "                total_sum += total_score\n",
    "                total_count += 1\n",
    "                prediction = int(total_sum / total_count > 58)\n",
    "                track_stat = track_stats.get(trackID_vec[nn], {})\n",
    "\n",
    "                csv_writer.writerow([userID, trackID_vec[nn], albumID_vec[nn],\n",
    "                                     artistID_vec[nn], *\n",
    "                                     user_rating_inTrain[nn], total_score,\n",
    "                                     track_stat.get(\n",
    "                                         'min', 0), track_stat.get('max', 0),\n",
    "                                     track_stat.get('mean', 0), track_stat.get(\n",
    "                                         'variance', 0),\n",
    "                                     track_stat.get('median', 0)])\n",
    "\n",
    "print(\"Total:\" + str(total_sum))\n",
    "print(\"Count: \" + str(total_count))\n",
    "print(\"Average: \" + str(total_sum/total_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+--------+-----------+------------+----------+---------+---------+------------------+------------------+------------+\n",
      "|UserId|TrackId|AlbumId|ArtistId|AlbumRating|ArtistRating|TotalScore|MinRating|MaxRating|        MeanRating|          Variance|MedianRating|\n",
      "+------+-------+-------+--------+-----------+------------+----------+---------+---------+------------------+------------------+------------+\n",
      "|199810| 208019| 209288|    None|        0.0|         0.0|       0.0|        0|      100|49.766129032258064|1349.9533688865763|        50.0|\n",
      "|199810|  74139| 277282|  271146|        0.0|         0.0|       0.0|       50|       90| 78.33333333333333|297.22222222222223|        90.0|\n",
      "|199810|   9903|   None|    None|        0.0|         0.0|       0.0|        0|      100|52.858823529411765|1339.4977162629757|        50.0|\n",
      "|199810| 242681| 190640|  244574|        0.0|         0.0|       0.0|        0|      100| 49.50834597875569|1692.7537239713458|        50.0|\n",
      "|199810|  18515| 146344|   33168|        0.0|        70.0|      70.0|        0|      100|  55.1566265060241|1373.2586006677311|        70.0|\n",
      "+------+-------+-------+--------+-----------+------------+----------+---------+---------+------------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from pyspark.sql.functions import split, col, avg\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('recommend-ML').getOrCreate()\n",
    "# import test_2 ground truths\n",
    "data_dir = \"../data/proccessed/test.csv\"\n",
    "df = spark.read.csv(data_dir, header=True, inferSchema=True)\n",
    "df.show(5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
